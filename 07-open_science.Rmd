# Open science practices {#open_science}

**Chapter lead author: Koen Hufkens**

## Introduction

The scientific method relies on repeated testing of hypothesis. When dealing with data and formal analysis one can reduce this problem to the question: could an independent scientist attain the same results given the data and code.

Although this seems trivial this issue has vexed the scientific community. These days, many scientific publications are based on complex analysis with often large data sets. More so, methods in publications often are insufficiently detailed to really capture the scope of an analysis. Even from this technical point of view, the reproducibility crisis or the inability to reproduce experimental results, is a complex problem.

This is further compounded by social aspects and incentives. The last decades scientific research has seen a steady increase in speed due to the digitization of many fields and the comodification of science.

Although digitization has opened up new research possibilities it also had less desired outcomes such as the reproducibility crisis, overall decreasing research quality, and outright fraud. Historically research (output) has been confined to academic journals with a limited reach into the public (civil) domain. Digitzation made both the academic output visible, as well as the issues that stem from it (e.g. fraud). In many ways the reproducibility crisis as digital tools have made this position untenable.

Open and reproducible science is in part a counter movement to make scientific research (output) accessible to the larger public, increase research transparency and countering accusations of fraud and limiting disinformation (to some extent). Open science therefore aims to be as open as possible about the whole scientific process, and as closed as desirable.

It is important to acknowledge that there is a spectrum of reproducible data and code workflows which depends on the state or source of the data and the output of the code (or analysis). Within the context of this course and the discussion of open science we focus solely on the practical aspects for reproducible science, i.e. ensuring that given the same data and code the results will be similar.

<!-- ![](https://the-turing-way.netlify.app/_images/reproducible-matrix.jpg) -->

For further reading on the topic of reproducibility from an epistemic, or the science of doing science, point of view and general open science practices facilitating other reproducibility modes as shown in the table above I refer to the reference list at the end of this section.

## Tutorial

The basics of open science coding and data practices rely on a number of simple concepts. The below sections describe a selection of the most important ones. Sticking to these principles and/or tools will increase the reproducibility of your work greatly.

### Project structure

Reproducible science relies on a number of key components. Data management and the tracking of required meta-data is the first step in an open science workflow. Although current computers make it easy to "find" your data and are largely file location agnostic this is not the case in many research environments. Here files need a precise, structured, location. This structure allows you to determine both the function and or order of a workflow.

It is good practice to have a consistent project structure within and between projects. This allows you to find most project components regardless of when you return to a particular project. Structuring a project in one folder also makes projects portable. All parts reside in one location making it easy to create a [github project]() from this location, or just copy the project to a new drive.

An example data structure for raw data processing is given below and we provided an [R project template](https://github.com/computationales/R_proj_template) to work from and adjust on the lab website. A full description on using the template is provided in the next section (\@ref(version-control)).

``` bash
data-raw/
├─ raw_data_product/
├─ 00_download_raw_data.R
├─ 01_process_raw_data.R
```

### Managing workflows

Although some code is agnostic to the order of execution many projects are effectively workflows, where the output of one routine is required for the successful execution of the next routine.

In order to make sure that a future you, or a collaborator, understands in which order things should be executed it is best to number scripts / code properly. This is the most basic approach to managing workflows.

In the example below all statistics code is stored in the statistics folder in an overall analysis folder (which also includes code for figures). All statistical analysis are numbered, to ensure that the output of a first analysis is available to the following one.

``` bash
analysis/
├─ statistics/
│  ├─ 00_random_forest_model.R
│  ├─ 01_random_forest_tuning.R
├─ figures/
│  ├─ global_model_results_map.R
│  ├─ complex_process_visualization.R
```

#### Automating and visualizing workflows with targets

To sidestep some of the manual management in R you can use dedicated pipeline tool like the **{targets} package** in R. The targets package learns how your pipeline fits together, skips tasks that are already up to date, runs only the necessary computation. Given the highly controlled environment {targets} can also visualize the (progress of) your workflow.

<!-- ![](https://books.ropensci.org/targets/man/figures/tar_watch.png) -->

Due to the added complexity of the targets package we won't include extensive examples of such a workflow but refer to the excellent documentation of the package for simple examples.

<https://books.ropensci.org/targets/walkthrough.html>

### Capturing your session state

Often code depends on various components, packages or libraries. These libraries and all software come in specific versions, which might or might not alter the behaviour of the cod which relies on them.

If you want to ensure full reproducibility, especially across several years, you will need to capture the state of the system and libraries with which you ran the original analysis.

In R the [{renv} package](https://rstudio.github.io/renv/) serves this purpose and will provide an index of all the packages used in your project as well as their version.For a particular project it will create a local library of packages with a static version. These static packages will not be updated over time, and therefore ensure consistent results. This makes your analysis, isolated, portable and reproducible. The analogue in python would be the [virtual environments, or venv program](https://docs.python.org/3/library/venv.html).

When setting up your project you can run:

``` r
# Initiate a {renv} environment
renv::init()
```

To initiate your static R environment. Whenever you want to save the state of your project (and its packages) you can call:

``` r
# Save the current state of the environment / project
renv::snapshot()
```

To save any changes made to your environment. All data will be saved in a project description file called a lock file (i.e. `renv.lock`). It is advised to update the state of your project regularly, and in particular before closing a project.

When you move your project to a new system, or share a project on github with collaborators, you can revert to the original state of the analysis by calling:

``` r
# On a new system, or when inheriting a project
# from a collaborator you can use a lock file
# to restore the session/project state using
renv::restore()
```

> NOTE: as mentioned in the {renv} documentation. "For development and collaboration, the `.Rprofile`, `renv.lock` and `renv/activate.R` files should be committed to your version control system. But the `renv/library` directory should normally be ignored. Note that renv::init() will attempt to write the requisite ignore statements to the project `.gitignore`." We refer to \@ref(learning-objectives-6) for details on github and its use.

### Capturing a system state

Although R projects and the use of targets make your workflow consistent the package versions used between various systems (e.g. your home computer, a cluster at the university etc. might vary). To address issues with changes in the versions of package you can use the {renv} package which manages package version (environments) for you. When tasks are even more complex and include components outside of R you can use [**Docker**](https://www.docker.com/) to provide containerization of an operating system and the included ancillary application.

The [{rocker} project](https://rocker-project.org/) provides access to some of these features within the context of reproducible R environments. Using these tools you can therefore emulate the state of a machine independent of the machine on which the docker file is run. These days Machine Learning applications are often deployed as docker sessions to limit the complexity of installing required software components. The application of docker based installs is outside the scope of the current course, but feel free to explore these resources as they are widespread in data science.

### Readable reporting using Rmarkdown

Within Rstudio you can use Rmarkdown dynamic documents to combine both text and code. Rmarkdown is ideal for **reporting** i.e., writing your final document presenting your analysis results. A Rmarkdown documents consists of a header document properties, such as how it should be rendered (as an html page, a docx file or a pdf), and the actual content.

Below you see the header file of an Rmarkdown document that should be rendered as an html page.

``` r
---
title: My R Markdown Report
author: You
output: html_document
---
```

The remainder of the document shows a code chunk outlined by \`\`\` quotes and the chunk arguments in {} brackets. Inline operations, the evaluation of code, in text is also possible by using single quotes around a variable or code.

```` bash
``` {r}
x <- 5  # radius of a circle
```

For a circle with the radius `r x`,
its area is `r pi * x^2`.
````

The document can be rendered by calling `rmarkdown::render()` on the command line or hitting the "Knit" button in the RStudio IDE. Depending on your settings a html file, pdf or docx file will be generated in your current directory (and or displayed in the IDE viewer).

``` r
# render the document on the command line
rmarkdown::render()
```

#### Referencing and finding files

In R projects all files can be referenced relative to the top most path of the project. When opening `your_project.Rproj` in RStudio you can load data in the console as such `read.table("data/some_data.csv")`, specifying a "soft" relative path for `some_data.csv`.

``` bash
project/
├─ your_project.Rproj
├─ statistics/
│  ├─ your_dynamic_document.Rmd
├─ data/
│  ├─ some_data.csv
```

Rmarkdown files are rendered relative to the file path where to document resides. This means that data which resides in `data` can't be accessed by `statistics/your_dynamic_document.Rmd` even when using an R project and soft relative paths (which work for scripts and functions). As such trying to render the `your_dynamic_document.Rmd` will fail as the file `some_data.csv` will not be found.

```` bash
---
title: Your dynamic document
author: You
output: html_document
---

```{r eval = FALSE}
data <- read.table('data/some_data.csv')
```
````

We need to explicitly take the project's base path into the fold using the [{here} package](https://here.r-lib.org/). The here package gathers the absolute path of files inside an R project. As such, `here::here("data/some_data.csv")` will return the full path of the data (e.g. `/your_computer/project/data/some_data.csv`). This absolute path will be a valid path for the read.table() function, making the Rmarkdown file render correctly. The correct Rmarkdown code to read the data therefore reads:

```` bash
---
title: Your dynamic document
author: You
output: html_document
---

```{r eval = FALSE}
data <- read.table(here::here('data/some_data.csv'))
```
````

But why not use absolute paths to begin with? Portability! When I would run your \*.Rmd file with an absolute path on my computer it would not render as the file `some_data.csv` would then be located at: `/my_computer/project/data/some_data.csv`

#### Limitations

The file referencing issue and the common use of Rmarkdown as a one size fits all solution, containing all aspects from data cleaning to reporting, makes Rmarkdown files not portable or reproducible. The one size fits all approach to Rmarkdown also encourages bad project management practices.

As illustrated above, if no session management tools such as the package {here} are used this automatically causes files to pile up in the top most level of a project, undoing most efforts to physically structure data and code as highlighted in \@ref(project-structure).

At the heart of this discussion are not only practical considerations but also the fact that R markdown documents mix two cognitive tasks, writing text content (i.e. reporting) and writing code. Switching between these two modes comes with undue overhead. If you code, you should not be writing prose, and vise versa.

If your R markdown file contains more code than it does text, it should be considered an R script or function (with comments or documentation). Conversely, if your markdown file contains more text than code it probably is easier to collaborate on a true word processing file (or cloud based solution). The use case where the notebooks might serve some importance is true reporting of general statistics.

R markdown files have their function for reporting concise results, once generated (through functions or analysis scripts) but should be generally be avoided to develop code & ideas as it encourages bad project management practices.

### Data retention

Coding practices and documenting all moving parts in a coding workflow is only one practical aspect of open science. An additional component is long term data and code retention and versioning.

For code online collaboration tools, such as [github](https://github.com), [gitlab](https://gitlab.com) or [codeberg](https://codeberg.org), provide a way to provide access to code. However, these tools should only be considered collaborative aids not a place to store code into perpetuity. Furthermore, these services mostly have a limit to how much data can realistically be stored in a repository (mostly \~2GB). For small projects data can be included in the repository itself, for larger projects this won't be possible.

To ensure long term storage of code and data, outside of commercial for profit services, it is best to rely on for example [Zenodo](https://zenodo.org/). Zenodo is an effort by the European commission, but accessible to all, to facilitate archiving of science projects of all nature (code and data) up to 50GB. In addition, Zenodo provides a citable digital object identifier or DOI. This allows data and code, even if not formally published in a journal, to be cited. Other noteworthy open science storage options include [Dryad](https://datadryad.org/stash) and the [Center for Open Science](https://osf.io/).

## Exercises

### Data and code management

#### External data

You inherit a project folder which contains the following files.

``` bash
~/project/
├─ survey.xlsx
├─ xls conversion.csv
├─ xls conversion (copy 1).csv
├─ Model-test_1.R
├─ Model-test-final.R
├─ Plots.R
├─ Figure 1.png
├─ test.png
├─ Rplot01.png
├─ Report.Rmd
├─ Report.html
```

What are your steps to make this project more reproducible? Write down how and why you would organize your project.

#### A new project

What are the basic steps to create a reproducible workflow from a file management perspective? Create your own project using these principles and provide details the on steps involved and why they matter.

The project should be a reproducible workflow:

-   to download and plot a MODIS land cover map for Belgium using skills you learned in \@ref(data_variety)

-   contain a function to count the occurrences of land cover classes in the map as a formal function using skills you learned in \@ref(data_wrangling)

-   create a plot of the land cover map (see \@ref(data_vis))

-   contain a dynamic report describing your answers to the above questions regarding how to structure a reproducible workflow

#### Tracking the state of your project

-   Track the packages you use in the project you created using {renv}

-   Install any additional library and update the state of your project

-   create a simple {targets} project using the above workflow

    -   make changes to the API download routine

    -   rerun the targets project

## References

-   complete references
