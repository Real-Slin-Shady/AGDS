# Programming primers {#programming_primers}

**Chapter lead author: Pepa Aran**

TBC

Contents:

- Lecture (Beni): Models and data
- Base R
- variables, classes
- data frames
- loops
- conditional statements
- functions
- input and output
- intro to visualisation
- Performance assessment: [link](https://stineb.netlify.app/files/ex1.pdf) to my exercise, [link to Dietze exercise](https://github.com/stineb/EF_Activities/blob/master/Exercise_01_RPrimer.Rmd)

## Learning objectives

After you've gone over the lecture and solved the exercises, you should be able to:

- Use loops and functions in your code
- Install and load libraries and packages
- Look for help
- Read, inspect and visualise data frames
- Organize your R project for data analysis

## Tutorial

### Libraries

*Packages*, also called *libraries*, are collections of R functions, data, and complied code in a well-defined format. R comes with a standard set of packages (including base R, utils, stats...) and other packages targeted for specific applications are available for download and installation. Once installed, you need to load them each time you start a new R session to use them.

For example, the `tidyverse` package is used for data wrangling and will be covered in this course. You can install a new package as follows:
```{r}
install.packages("tidyverse")
```

Then, you can load it with the following code. Note that now the name of the package is not in quotation marks.
```{r}
library(tidyverse)
```
You can now use the functions and features provided by the `tidyverse` package in your R scripts.

You can see a list of your installed packages with the following command:
```{r}
library()
```
*
And a list of the packages currently loaded:
```{r}
search()
```

This information can also be found on the **Packages** panel in RStudio. The loaded packages are shown with a tick mark.

#### Other libraries and applications

For this course, we will also need software that is not available as an R package. To work with other libraries and applications, you may need to install additional software on your computer. 

For example, to work with *netcdf* files in R, you would need to install the `"ncdf4"` library and the `netCDF` command-line tools:
- To install the `"ncdf4"` library, follow the same steps as above for installing an R library.
- To install the `netCDF` command-line tools, follow the instructions on the [netCDF website]{https://www.unidata.ucar.edu/downloads/netcdf/index.jsp}.
- Once the `"ncdf4"` library and the `netCDF` command-line tools are installed, you can use them to work with `.nc` files in R. For example, you could use the `nc_open()` function from the `"ncdf4"` library to open a file.

### Working with data frames

In the first tutorial, we introduced data frames as an R object. Now, let's get our hands on actual data for demonstrating how data is read and written. As most of the code displayed in this book, the code chunks below are executable. You can try it out by opening the the book's R project in RStudio. 

We are going to work with data from ecosystem flux measurements, taken by the eddy covariance technique, and provided as part of the FLUXNET2015 dataset [@Pastorello2020], which you can [see here](https://www.nature.com/articles/s41597-020-0534-3). The data we're using below comes from a flux tower near Zürich ([CH-Lae](https://gl.ethz.ch/research/bage/fluxnet-ch.html), located on the Laegern mountain between Regensberg and Baden and run by our colleagues at ETH).

The data is stored as a Comma Separated Values file (`.csv`). This is a plain-text, and therefore a non-proprietary format. To follow the open science principles for data, distribute your data in a format that is non-proprietary and readable across platforms and applications. For example, avoid distributing your data as an *Excel* spreadsheat (`.xlsx`), or a *Matlab* data object (`.mat`), or an R data object (`.RData`, or `.rds`). 

#### Reading data

To import the data into the R environment, we use the function `read_csv()` from the tidyverse package. In other R code, you will also encounter the base R `read.csv()` function. However, `read_csv()` is much faster and reads data into a tidyverse-data frame (a *tibble*) which has some useful additional characteristics, on top of a common R data frame. To tell the function where the data is located, pass the data's path as an argument. You can either use an *absolute path*, starting from `C:/` on a Windows computer or `~/` on a Mac or Linux. Or, alternatively, you can provide a *relative path*, where `./` points to the present working directory and `../` is one level up, or `../../` is two levels up, etc. We recommend that you work with R projects and use relative paths, because the working directory is set to the root directory of the R project and relative paths will also work on another person's computer, helping with reproducibility.

```{r message=FALSE}
# use a relative path to read the data
df <- read_csv("./data/FLX_CH-Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv")
print(df) # to print an overview of the data frame
```

The file is automatically machine-readable because we have:

- Only one header row, containing the column (variable) names.
- Variables organised by columns, and observations by rows.
- Each column consists of a single data type (e.g., character, numeric, logical; see below for more info). Here, all columns are interpreted as numeric (`<dbl>').
- One value per cell.
- No merged cells.
In short, the data frame is tidy.
To understand the sort of object we work with, i.e. the *class*, we can do:
```{r}
class(df)
```

Fundamentally, `df` is a `data.frame`. In addition, it is also of some other classes (`spec_tbl_df", "tbl_df", "tbl"`) which gives it additional features. 

#### Understanding the data structure

There are several base R functions to help you understand the structure of a data frame. Here is a non-exhaustive list of of them:

- Size
  - `dim()`  - Returns the dimensions of an object (here: number of rows and columns).
  - `nrow()` - Returns the number of rows of an object.
  - `ncol()` - Returns the number of columns of an object.
- Content
  - `head()` - Returns the first 6 rows.
  - `tail()` - Returns the last 6 rows.
  - `View()` - Opens a window in the source panel in RStudio where you can look at the entire data set in the form of a table (It is not supported by the Jupyter environment).
- Names
  - `names()` - Returns the column names (for `data.frame` objects it is synonymous to `colnames()`).
  - `rownames()` - Returns the row names.
- Summary
  - `class()` - Returns the classes of an object.
  - `str()` - Returns the structure of an object and information about the class, length and content of each column.
  - `summary()` - Returns generic statistics information, depending on the class of the object. For categorical variables it will show how common each class is, missing values, etc, and for numerical variables, the mean, quantiles, maximum and minimum values, etc.
  
For example, the data frame `df` has 4018 rows and 334 columns:

```{r}
dim(df)
```

It is important to know the meaning of the column namesA description of standardized FLUXNET data variables is available [here](https://fluxnet.org/data/aboutdata/data-variables/). A selection of available variables that we will use in subsequent chapters are:

- `GPP` (gC m$^{−2}$ s$^{-1}$): Gross primary production
- `WS` (m s$^{-1}$): Horizontal wind speed
- `USTAR` (m s$^{-1}$): Friction velocity
- `TA` ($^{o}$ C): Air temperature
- `RH` (%): Relative humidity (range 0–100%)
- `PA` (kPa): Atmospheric pressure
- `G` (W m$^{−2}$): Ground heat flux, not mandatory, but needed for the energy balance closure calculations
- `NETRAD` (W m$^{−2}$): Net radiation, not mandatory, but needed for the energy balance closure calculations
- `SW_IN` (W m$^{−2}$): Incoming shortwave radiation
- `SW_IN_POT` (W m$^−2$): Potential incoming shortwave radiation (top of atmosphere theoretical maximum radiation)
- `PPFD_IN` ($\mu$mol photons m$^{−2}$ s$^{-1}$): Incoming photosynthetic photon flux density
- `P` (mm): Precipitation total of each 30 or 60 minute period
- `LW_IN` (W m$^{−2}$): Incoming (down-welling) long-wave radiation
- `SWC` (%): Soil water content (volumetric), range 0–100%
- `TS` ($^{o}$ C): Soil temperature
- `CO2` ($\mu$molCO~2~ mol$^{-1}$): Carbon dioxide (CO$_2$) mole fraction in moist air

#### Selecting data and entering the tidyverse

`df` is a data frame. This is similar to a matrix and has two dimensions (rows and columns). If we want to extract specific data from it, we specify the indices, i.e. the "coordinates", of the data. For two-dimensional objects (data frames, matrices), the first index refers to rows and the second to columns. For example, to refer to the element on the third row in the first column, we write:
```{r}
df[3,1]
```

Reducing a data frame (tibble) to only the first columns can be done by:
```{r}
df[, 1]
```

The method of selecting parts of a data frame by index is quite flexible. For example, we may require the information in the third column for the first three rows. Putting a colon between two numbers, e.g. `[1:3,]`, indicates we want to select the rows numbers starting at the first and ending with the second number. So here `[1:3,]` will give us rows one, two and three.
```{r}
df[1:3, 3] # reduces the data frame (tibble) to its first three rows and the 3rd column
```

To reduce the data frame (tibble) to several columns, the function `c()` is used. `c()` stands for concatenate, which means to link together in a series or chain. This outputs the data frame (tibble) reduced to the selected row or column numbers inside `c()`. 
```{r}
df[, c(1,4,7)]
```

Another method is to select the columns by column names, i.e. giving as input a string vector with the name of each column we want to select (again, this is Base R notation). This is especially useful if the columns we want to select are not contiguous. For example:

```{r}
# Selecting data by name in base R
df[,c("TIMESTAMP", "TA_F_MDS", "TA_F_MDS_QC")]
```

In [Tutorial 3]{#data_wrangling}, we will use the [tidyverse](https://www.tidyverse.org/), which is a set of R packages designed for working with tidy data and writing code in a way that makes the "workflow" more clear and understandable. A code chunk which does the same as above, but is written for the tidyverse can read as follows.

```{r}
select(df, 1) # reduces the data frame (tibble) to its first column
select(df, TIMESTAMP, TA_F_MDS, TA_F_MDS_QC)  # reduces the data frame to columns specified by names
```

As a further shortcut in tidyverse, we can use the pipe `%>%` operator. The data frame is still reduced to its first column:

```{r}
df %>% select(1)
```

We *pipe* the object `df` into the `select()` function with argument `1`. Note that the pipe operator `%>%` can be used on any function. It tells the function to interpret what's coming from the left of `%>%` as its **first** argument.

For the remainder of the tutorial several variables will be required. The methods of data selection demonstrated above will be used below to get the desired variables.

```{r}
df_small <- df %>% 
  select(TIMESTAMP, TA_F, PPFD_IN)
```

Note: In the code above, an indentation was used to highlight which parts go together, which makes the code easy to understand. Indentations and line breaks have no meaning or function in R per se (unlike in other programming languages, e.g., Matlab, Python), but help to make the code easier to read.
 
#### Renaming

TIMESTAMP_START, TA_F and PPFD_IN as variable names may be hard to remember and in this section you will have to type them a lot. Therefore we change their names to something more intelligible.

```{r}
df_small <- df_small %>% 
  rename(time = TIMESTAMP, temp = TA_F, ppfd = PPFD_IN)
```

#### Writing data

A data frame can be written to a CSV file by:

```{r, eval = F}
write_csv(df_small, path = "data/df_small.csv")
```

The function `saveRDS()` allows you save individual R objects of any form (not just a data frame). `saveRDS()` creates a binary file that is fast to write and read, but only intelligible to R. Such files are commonly identified by the suffix `.rds`. It is recommended to name the `.rds` files according to the single object they contain. For example:

```{r, eval=F}
saveRDS(df_small, file = "data/df_small.rds")
```

This file can then be read into the R environment. Sometimes, it is useful to give it a new name, e.g.:

```{r, eval=F}
df_small <- readRDS("data/df_small.rds")
```

Note that making a file publicly available as a `.rds` file violates the open science principles. It is not *interoperable*. Therefore, whenever possible, save your data in a format that is readable across platforms without requiring proprietary software. Hence use `write_csv()` whenever possible. We will encounter other non-proprietary formats that let you save and share more complex data structures in [Tutorial 5]{#data_variety}.

### Programming basics

In this section, we will review the most basic programming elements (conditional statements, loops, functions...) for the R syntax.

#### Conditional statements

In cases where we want certain statements to be executed or not, depending on a criterion, we can use *conditional statements* `if`, `else if`, and `else`. Conditionals are an essential feature of programming and available in all languages. The R syntax for conditional statements looks like this:

```{}
if (temp < 0.0){
  is_frozen <- TRUE
}
```

The evaluation of the criterion (here `(temp < 0.0)`) has to return either `TRUE` or `FALSE`. Whenever the statement between parenthesis is true, the chunk of code between curly brackets is executed. Otherwise, nothing happens.

```{}
if (temp < 0.0){
  is_frozen <- TRUE
} else {
  is_frozen <- FALSE
}
```

You can also write a conditional that covers all possibilities, like the one above. When the temperature is below 0, the first chunk of code is executed. Whenever it is greater or equal that 0 (i.e. the condition returns `FALSE`) the second chunk of code is evaluated.

You can also write more than two conditions, covering several cases. Conditionals are evaluated in order, so if the first condition is not true, it checks the second. If the second is false, it checks the third, and so on. The statements after `else` are evaluated when everything before was `FALSE`.

#### Loops

*Loops* are another essential feature of programming. `for` and `while` loops exist in probably all programming languages. We introduce them here because they are a simple and powerful tool for solving many common tasks.
  
`for` and `while` loops let us repeatedly execute the same set of commands, while changing an index or counter variable to take a sequence of different values. The following example calculates the sum of the first ten temperature values in `df`, by iteratively adding them together. Of course, this is equivalent to just using the `sum()` function. 

```{r}
temp_sum <- 0   # initialize sum
for (i in 1:10){
  temp_sum <- temp_sum + df_small$temp[i]
}
print(temp_sum)

print(sum(df_small$temp[1:10]))
```

Instead of directly telling R how many iterations it should do we can also define a condition. As long as the condition is `TRUE`, R will continue iterating. As soon as it is `FALSE`, R stops the loop. The following lines of code do the same operation as the `for` loop we just wrote. What is different? What is the same?

```{r}
i = 1           # initialize counter
temp_sum <- 0   # initialize sum
while (i <= 10){
  temp_sum <- temp_sum + df_small$temp[i]
  i = i+1
}
print(temp_sum)

print(sum(df_small$temp[1:10]))
```

#### Functions

Often, analyses require many steps and your scripts may get excessively long. Over 2000 lines of code in one file are hard to digest. An important aspect of good programming is to avoid duplicating code. If the same sequence of multiple statements or functions are to be applied repeatedly to different objects, then it is usually advisable to bundle them into a new *function* and apply this single function to each object. This also has the advantage that if some requirement or variable name changes, it has to be edited only in one place. A further advantage of writing functions is that you can give the function an intuitively understandable name, so that your code reads like a sequence of orders given to a human.

For example, the following code, converting temperature values provided in Fahrenheit to degrees Celsius, could be turned into a function.
```{}
## NOT ADVISABLE
temp_soil <- (temp_soil - 32) * 5 / 9
temp_air  <- (temp_air  - 32) * 5 / 9
temp_leaf <- (temp_leaf - 32) * 5 / 9
```

Functions are a set of instructions encapsulated within curly brackets (`{}`) that generate a desired outcome. Functions contain three main elements: 
-   They start with a _name_ to describe their purpose, 
-   then they need arguments, which are a list of the objects being input,
-   and lastly enclosed by curly brackets `function(x){ ... }` the code making up the 'body' of the function.

They become increasingly important the more experienced one gets at coding. Using functions minimises the amount of code being re-written, decreases accidental errors when retyping code and are key to keeping a clean workspace. Functions have their own environment, which means variables within the function are only 'live' or used when the function is running but are not saved to the global environment unless they are part of the output of the function. A good moment to think about using a function is when sections of code are being repeated again and again. 

Whenever possible, we should combine multiple processing steps that naturally belong together. Specifically, when the same sequence of steps must be applied to multiple datasets that have the same structure (variable names, etc.). We can combine the set of operations presented above into a single function. Once such a function is created, we can apply it to the data in one go, instead of repeating the successive steps.

We will now write our first function and implement the data cleaning steps we described above. The function consists of multiple sequences of code as it contains the different steps presented above and applies them sequentially.

The same, but using our own function `convert_fahrenheit_to_celsius()`:
```{}
## ADVISABLE
convert_fahrenheit_to_celsius <- function(temp_f){
  temp_c <- (temp_f - 32) * 5 / 9
}

temp_soil <- convert_fahrenheit_to_celsius(temp_soil)
temp_air  <- convert_fahrenheit_to_celsius(temp_air)
temp_leaf <- convert_fahrenheit_to_celsius(temp_leaf)
```

Functions (particularly long ones) can be written to separate source files. These R scripts containing only function definitions can be saved in your `./R` directory, to keep your workspace organized. Preferably, the file has the same name as the function.

#### Input and output

A good practice when writing a function is to document what the function does, the meaning and structure of every input (argument) and the output (value) of the function. 

### Intro to visualisation

Visualising data is an integral part of any data science workflow. In this section, we introduce just the very basics. In later tutorials, you will get introduced to additional methods for visualising data. Our data frame `fluxes_subset` contains three variables, one of which is `time`. In other words, we are dealing with a time series. Let's look at the temporal course of temperature in the first 1440 time steps (corresponding to 30 days) as a line plot (`type = "l"`).

```{r}
plot(1:1440, df_small$temp[1:1440], type = "l") 
```

Another useful way of looking, not at a temporal course, but rather at the distribution of your data, is to display a histogram. 
A histogram visualises the frequency or proportion of data that has a metric value that falls within a certain interval known as a 'bin'. Below you will see the temperature on the x-axis split into these 'bins' ranging across 2°. The number of times a data point falls between say 2° to 4° is then tallied and displayed as the frequency on the y-axis. Here there are around 1500 temperature values between 2° and 4°.

```{r}
hist(df_small$temp, xlab = "Temperature (°C)")
```

Plots can be saved as files, as long as the file size does not get too large.It will write vector graphics as outputs, i.e. PDF. In base R, this can be done by:

```{r eval=F}
pdf("./figures/filename.pdf")
hist(df_small$temp)
```

### Where to find help



## Exercises

## Solutions
