# (APPENDIX) Appendix {-}

# Solutions {#solutions}

## Getting Started

### Dimensions of a circle {-}

- Given the radius of a circle write a few lines of code that calculates its area and its circumference. Run your code with different values assigned of the radius. 
```{r}
radius <- 1
area <- pi * radius^2
circum <- 2 * pi * radius
```
- Print the solution as text.
```{r}
print(paste("Radius:", radius, "   Circumference:", circum))
```

### Sequence of numbers {-}

Generate a sequence of numbers from 0 and $\pi$ as a vector with length 5.
```{r}
seq(0, pi, length.out = 5)
```

### Gauss sum {-}

Rumors have it that young Carl Friedrich Gauss was asked in primary school to calculate the sum of all natural numbers between 1 and 100. He did it in his head in no time. We're very likely not as intelligent as young Gauss. But we have R. What's the solution?

```{r}
sum(1:100)
```

Gauss calculated the sum with a trick. The sum of 100 and 1 is 101. The sum of 99 and 2 is 101. You do this 50 times, and you get $50 \times 101$. Demonstrate Gauss' trick with vectors in R.
```{r}
vec_a <- 1:50
vec_b <- 100:51
vec_c <- vec_a + vec_b

# each element is 101
vec_c

# the length of vectors is fifty. 50 * 101
sum(vec_c)
```

### Magic trick algorithm {-}

Define a variable named `x` that contains an integer value and perform the following operations in sequence:

- Redefine `x` by adding 1.
- Double the resulting number, over-writing `x`.
- Add 4 to `x` and save the result as `x`.
- Redefine `x` as half of the previous value of `x`.
- Subtract the originally chosen arbitrary number from `x`.

Print `x`. Restart the algorithm defined above by choosing a new arbitrary natural number.

```{r}
x <- -999  # arbitrary integer
x_save <- x  # save for the last step
x <- x + 1
x <- x * 2
x <- x + 4
x <- x / 2
x - x_save
```

### Vectors {-}

Print the object `datasets::rivers` and consult the manual of this object.

- What is the class of the object? 
- What is the length of the object?
- Calculate the mean, median, minimum, maximum, and the 33%-quantile across all values. 

```{r}
class(datasets::rivers)
length(datasets::rivers)
mean(datasets::rivers)
# other functions can easily be found on the internet ;-)
```

### Data frames {-}

Print the object `datasets::quakes` and consult the manual of this object.

- Determine the dimensions of the data frame using the respective function in R.
- Extract the vector of values in the data frame that contain information about the Richter Magnitude.
- Determine the value largest value in the vector of event magnitudes.
- Determine the geographic position of the epicenter of the largest event.

```{r}
dim(datasets::quakes)
vec <- datasets::quakes$mag
max(vec)
idx <- which.max(vec)  # index of largest value

# geographic positions defined by longitude and latitude (columns long and lat)
datasets::quakes$long[idx]
datasets::quakes$lat[idx]
```

### Workspace {-}

Create a new *R project* and create sub-directories in a meaningful way (as described in this Chapter). Create an RMarkdown file in your new project which implements your solutions to above exercises. Give the file a title, implement some structure in the document, and write some text explaining what your code does.

*No solutions provided.*

## Programming primers

### Gauss variations {-}

Use a `for` loop to compute the sum of all natural numbers from 1 to 100. Print the result to the screen. Repeat this exercise but use a `while` loop.
```{r}
# 1a. for-loop to compute sum from 1 - 100
sum <- 0
for (i in 1:100){
  sum <- sum + i # for-loop iterating from 1 to 100 
}
print(sum)

# 1b. while-loop to compute sum from 1 - 100
loop_status <- TRUE
counter <- 0
sum <- 0
while (loop_status) { # while-loop is repeated as long as loop_status is true
  counter <- counter + 1
  sum <- sum + counter
  if (counter == 100) loop_status <- FALSE
}
print(sum)
```

Add up all numbers between 1 and 100 that are at the same time a multiple of 3 and a multiple of 7. Print the result to the screen in the form of: `The sum of multiples of 3 and 7 within 1-100 is: {your result}`.
```{r}
sum <- 0
for (i in seq(100)) {
	if (i %% 3 == 0 && i %% 7 == 0 ) {
		sum <- sum + i
	}	
}	
print(paste0("The sum of multiples of 3 and 7 within 1-100 is: ", sum))
```

### Nested loops {-}

Given a matrix `mymat` and a vector `myvec` (see below), implement the following algorithm:

1. Start with the first row in `mymat`.
2. Fill all missing values in the current row of `mymat` with the maximum value in `myvec`.
3. Drop the maximum value from `myvec`.
4. Proceed to the next row of `mymat` and repeat steps 2-4.

`mymat` and `myvec` are defined as:
```{r}
mymat <- matrix(c(6, 7, 3, NA, 15, 6, 7, 
              NA, 9, 12, 6, 11, NA, 3, 
              9, 4, 7, 3, 21, NA, 6, 
              rep(NA, 7)),
            nrow = 4, byrow = TRUE)
myvec <- c(8, 4, 12, 9, 15, 6)
```

```{r message=FALSE}
for (i in 1:nrow(mymat)){
  for (j in 1:ncol(mymat)){
    if (is.na(mymat[i,j])){
      mymat[i,j] <- max(myvec)
    }
  }
  myvec <- myvec[-which.max(myvec)] # update the B vector removing the maximum value
}
mymat
```

### Interpolation {-}

Define a vector $\vec{v}$ of length 100. Define the vector so that $v_i = 6$, for $i = 1 : 25$ and $v_i = -20$, for $i = 66 : 100$. Remaining elements are to be defined as 'missing'. Linearly interpolate missing values that are not defined. Plot the values of $\vec{v}$ using `plot(vec)`.

```{r}
vec <- rep(NA, 100) # initialize vector of length 100 with NA
vec[1:25] <- 6      # populate first 25 elements of 'vec' with 6. 
vec[66:100] <- -20  # populate elements 66:100 with -20.

# Determine index of last non-missing value before gap
last_non_na <- 1
while (!is.na(vec[last_non_na+1])) last_non_na <- last_non_na + 1

# determine index of first non-missing value after gap
first_non_na <- last_non_na + 1
while (is.na(vec[first_non_na])) first_non_na <- first_non_na + 1	

# Get the increment that is needed for interpolation
last_value  <- vec[last_non_na]  # Last non-NA value
first_value <- vec[first_non_na] # First non-NA value
delta <- (last_value - first_value) / (last_non_na - first_non_na) # Change in y over change in x

# fill missing values incrementally
for (i in 2:length(vec)){
  if (is.na(vec[i])) vec[i] <- vec[i-1] + delta
}

plot(vec)

# or short using the approx() function:
vec <- rep(NA, 100) # initialize vector of length 100 with NA
vec[1:25] <- 6      # populate first 25 elements of 'vec' with 6. 
vec[66:100] <- -20  # populate elements 66:100 with -20.

vec <- approx(1:100, vec, xout = 1:100)

plot(vec)
```

## Data wrangling

### Star wars {-}

{dplyr} comes with a toy dataset `dplyr::starwars` (just type it into the console to see its content). Have a look at the dataset with `View()`. Play around with the dataset to get familiar with the {tidyverse} coding style. Use (possibly among others) the functions `dplyr::filter()`, `dplyr::arrange()`, `dplyr::pull()`, `dplyr::select()`, and `dplyr::slice()` to answer the following questions (hint: find the function names online or use the `Help` tab in RStudio):

a.  How many pale characters come from the planets Ryloth or Naboo?
```{r message=FALSE}
dplyr::starwars |> 
  dplyr::filter(skin_color == "pale" & (homeworld == "Naboo" | homeworld == "Ryloth")) |> 
  nrow()   
```

b.  Who is the oldest of the tallest thirty characters?
```{r message=FALSE}
dplyr::starwars |> 
  arrange(desc(height)) |> 
  slice(1:30) |> 
  arrange(birth_year) |> 
  slice(1) |> 
  pull(name)
```

c.  What is the name of the shortest character and their starship in "Return of the Jedi"?
```{r message=FALSE}
dplyr::starwars |> 
  select(name, starships, films, height) |> 
  unnest(films) |> 
  filter(films == "Return of the Jedi") |> 
  unnest(starships) |> 
  arrange(height) |> 
  slice(1)
```

> Use `unnest()` to expand columns that contain lists inside cells. The expansion of such columns creates additional rows in the data frame if the cell contained a list with more than one element. 

### Aggregating {-}

Reuse the code in the tutorial to read, reduce, clean, and aggregate the `hhdf` dataset to the daily scale, calculating the following metrics across half-hourly `VPD_F` values for each day: maximum value, minimum value, median, and standard deviation.
```{r}
# Load and wrangle the hhdf dataset
hhdf <- read_csv("data/FLX_CH-Lae_FLUXNET2015_FULLSET_HH_2004-2006.csv") |>
  dplyr::select(
    starts_with("TIMESTAMP"),
    ends_with("_F"),
    GPP_NT_VUT_REF,
    NEE_VUT_REF_QC,
    starts_with("SWC_F_MDS_"),
    -contains("JSB"),
    NIGHT
  )

# Get different statistics for VPD_F
ddf <- hhdf |>  
  mutate(date_time = lubridate::ymd_hm(TIMESTAMP_START),
         date      = lubridate::date(date_time)) |>
  group_by(date) |> 
  summarise(VPD_F_mean   = mean(VPD_F),
            VPD_F_median = median(VPD_F),
            VPD_F_min    = min(VPD_F),
            VPD_F_max    = max(VPD_F),
            VPD_F_sd     = sd(VPD_F))

ddf
```


### Patterns in data quality {-}

The uncleaned dataset `FLX_CH-Lae_FLUXNET2015_FULLSET_HH_2004-2006.csv` holds half-hourly data that is sometimes of poor quality. Investigate whether NEE data quality is randomly spread across hours in a day by calculating the proportion of (i) actually measured data, (ii) good quality gap-filled data, (iii) medium quality data, and (iv) poor quality data within each hour-of-day (24 hours per day).

```{r}
# using hhdf read above
df <- hhdf |> 
  mutate(TIMESTAMP_START = lubridate::ymd_hm(TIMESTAMP_START)) |> 
  mutate(hod = lubridate::hour(TIMESTAMP_START)) |> 
  group_by(hod) |> 
  summarise(n_measured = sum(NEE_VUT_REF_QC == 0),
            n_good     = sum(NEE_VUT_REF_QC == 1),
            n_medium   = sum(NEE_VUT_REF_QC == 2),
            n_poor     = sum(NEE_VUT_REF_QC == 3),
            n_total    = n()
            ) |> 
  mutate(f_measured = n_measured / n_total,
         f_good     = n_good     / n_total,
         f_medium   = n_medium   / n_total,
         f_poor     = n_poor     / n_total,
         )

# this is not asked for but interesting. More on data visualisation in Chapter 5
df |> 
  pivot_longer(c(f_measured, f_good, f_medium, f_poor), 
               names_to = "quality", 
               values_to = "fraction") |> 
  ggplot(aes(x = hod, y = fraction, color = quality)) +
  geom_line()
```
