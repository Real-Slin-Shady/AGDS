[["index.html", "Applied Geodata Science About this book", " Applied Geodata Science Benjamin Stocker (lead), Koen Hufkens (contributing), Pepa Aran (contributing), Pascal Schneider (contributing) 2023-01-05 About this book This book accompanies the course(s) Applied Geodata Science, taught at the Institute of Geography, University of Bern. The course introduces the typical data science workflow using various examples of geographical and environmental data. With a strong hands-on component and a series of input lectures, the course introduces the basic concepts of data science and teaches how to conduct each step of the data science workflow. This includes the handling of various data formats, the formulation and fitting of robust statistical models, including basic machine learning algorithms, the effective visualisation and communication of results, and the implementation of reproducible workflows, founded in Open Science principles. The overall course goal is to teach students to tell a story with data. "],["course-plan.html", "Course plan", " Course plan Getting started Programming primer Data wrangling Data visualisation Data variety Code management Open Science practice MILESTONE 1: Communicating a reproducible workflow (→ LO1) Regression Supervised machine learning fundamentals Random Forest Neural Networks Interpretable machine learning Unsupervised machine learning MILESTONE 2: Identify patterns and demonstrate how explained (→ LO2) "],["getting_started.html", "Chapter 1 Getting started 1.1 Learning objectives 1.2 Tutorial 1.3 Exercises 1.4 Solutions", " Chapter 1 Getting started Chapter lead author: Pepa Aran TBC Contents: Lecture (Beni): Data revolution, opportunities, challenges; explain relevance and why new methods are required installing environment workspace management R, RStudio R libraries, other libraries and applications 1.1 Learning objectives After you’ve gone over the lecture and solved the exercises, you should be able to: Work with R and RStudio on your computer Know some R objects and basic classes Follow basic good coding practices Organize your workspace using R projects Save your code and progress in an organized way 1.2 Tutorial 1.2.1 Working with R and RStudio R is a free, open-source programming language and software environment for statistical computing and graphics. It is widely used among statisticians and data miners for developing statistical software and data analysis. RStudio is an integrated development environment (IDE) for R that makes it easy to use R for data analysis and visualization. 1.2.1.1 Installing R and RStudio To use R and RStudio, you will first need to download and install them on your computer. To install R, go to the CRAN website and download the latest version of R for your operating system. Once the download is complete, follow the on-screen installation instructions for your operating system to install R. To install RStudio, go to the RStudio website and download the latest version of RStudio for your operating system. Once the download is complete, follow the installation instructions for your operating system to install RStudio. 1.2.1.2 The RStudio interface RStudio provides a user-friendly interface for writing, running, and debugging R code. When you open RStudio, you will see the following: RStudio interface. The interface is divided into four main panels: The source editor is where you can write, edit, and save your R code. The console is where you can enter R commands and see the output. The environment panel shows you the objects (variables, data frames, etc.) that are currently in your R session, as well as their values. The files, plots, help, etc. panel shows you the files, plots, and other items that are currently in your R workspace, as well as help and documentation for R functions and packages. We will cover this in more detail later in this course. 1.2.1.3 Running R code Once you have both programs installed, you can open RStudio and begin a new R session. To run R code using R Studio, follow these steps: In the source editor panel, type your R code. To run the code, you can either press the Run button or use the keyboard shortcut Ctrl + Enter (Windows) or Command + Enter (Mac). The code will be executed in the console panel, and any output will be displayed there. Alternatively, you can directly type single-statement R commands in the console and run them by pressing Enter. For example, let’s say you want to calculate the sum of the numbers 1, 2, and 3. You can write the following code in the source editor: # Calculate the sum of 1, 2, and 3 1 + 2 + 3 ## [1] 6 Then, you can press the Run button or use the keyboard shortcut to run the code. The output will be displayed in the console: &gt; 1 + 2 + 3 [1] 6 1.2.1.4 Base R operations The R base package contains the basic functions which let R function as a programming language: arithmetic, input/output, basic programming support, etc. Its contents are always available when you start an R session. Here we introduce the main binary operators, which work on vectors, matrices and scalars. Arithmetic operators: + addition - subtraction * multiplication / division ^ or ** exponentiation Logical operators: &gt; greater than &gt;= greater than or equal to == exactly equal to &lt; less than &lt;= less than or equal to != not equal 1.2.2 R objects In addition to running single statements in the R console, the output of a statement can be saved as a new object. There are many kinds of R objects, some of which are covered here and in Tutorial 2. 1.2.2.1 Variables and classes In R, a variable is a named location in memory that stores a value. To create a variable, you simply assign a value to a name using the &lt;- operator (or the = operator, which is equivalent, but &lt;- is preferred). For example: my_variable &lt;- 5 This code creates a variable called my_variable and assigns the value 5 to it. You can access the value of a variable or any other object by simply referring to its name, like this: my_variable ## [1] 5 When you run this code, the value of my_variable will be printed to the console. In R, every object and value has a class that determines how it is stored and how it behaves. For example, the 5 in our example above is a number, so its class is numeric. To find out the class of a value or a variable, you can use the class() function, like this: class(5) # returns &quot;numeric&quot; ## [1] &quot;numeric&quot; class(my_variable) ## [1] &quot;numeric&quot; The most basic classes are: numeric (num) - any real number, e.g. 2.375 integer (int) - integer numbers, e.g. 2 character (chr) - any string, e.g. “fluxes” logical (logi) - boolean, i.e. TRUE/FALSE values factor (Factor) - categorical data, the variable can only be one of a defined amount of options, e.g. female/male/other function - a set of statements organized to perform a specific task, for example mean() By default, any number is coerced as \"numeric\". So if you want an integer value to have class \"integer\", you need to specify it like this: my_variable &lt;- as.integer(5) class(my_variable) # returns &quot;integer&quot; ## [1] &quot;integer&quot; Sometimes you need to convert the class of an object, for example turning a \"integer\" number into a \"character\". You can do so as follows: my_variable &lt;- as.character(my_variable) my_variable ## [1] &quot;5&quot; class(my_variable) # returns &quot;character&quot; ## [1] &quot;character&quot; Notice that now the values are in quotes \"5\". This way, R interprets it as a text and you will not be able to do any numeric calculations with it anymore. 1.2.2.2 Vectors A vector in R is a sequence of data elements of the same class. Vectors can be created with the c() function, which stands for concatenate. For example, the following code creates a numeric vector: x &lt;- c(1, 2, 3, 4, 5) To access the elements of a vector, you can use the square bracket notation. For example, the following code retrieves the second element of the vector x: x[2] ## [1] 2 You can also use the square bracket notation to extract a subvector from a larger vector. For example, you can extract the second to fourth elements of the vector x: x[2:4] ## [1] 2 3 4 Another useful property of vectors in R is that they can be easily combined using arithmetic operators. For example, adding the elements of two vectors x and y element-wise: x &lt;- c(1, 2, 3) y &lt;- c(4, 5, 6) x + y ## [1] 5 7 9 R also supports vectors of other classes, for example character vectors. Since all elements must be of the same class, the most general class will be adopted. The following code concatenates the vectors x and y, followed by new character elements: z &lt;- c(x, y, &quot;seven&quot;, &quot;eight&quot;) z ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;seven&quot; &quot;eight&quot; class(z) ## [1] &quot;character&quot; Operations on vectors are performed element-wise. For example, if we ask what numbers in x are greater than 2, we obtain a vector of logical values (and class \"logical\"): x &gt; 2 ## [1] FALSE FALSE TRUE 1.2.2.3 Lists Lists are another R object, of class \"list\". They are extremely flexible. They allow us to store different types of data, even if they are of different lengths or classes. They are created with the function list() and can be named or not. Here is an example where each element of the list is named. mylist &lt;- list( temperatures = c(2.234, 1.987, 4.345), my_favourite_function = mean, best_course = &quot;Applied Geodata Science&quot; ) Similar to vectors, we can extract elements from lists, either by index [[1]] or by the name using [[\"temperatures\"]] or $temperatures. Note the double [[]] here, indicating an element of a list as opposed to [] indicating an element of a vector. To get the entire vector of temperatures, do either of the three: mylist[[1]] ## [1] 2.234 1.987 4.345 mylist[[&quot;temperatures&quot;]] ## [1] 2.234 1.987 4.345 mylist$temperatures ## [1] 2.234 1.987 4.345 And to get the first temperature value: mylist[[&quot;temperatures&quot;]][1] ## [1] 2.234 You can also append elements to the list (either way is possible): mylist[[&quot;my_second_favourite_function&quot;]] &lt;- median mylist$my_second_favourite_function &lt;- median This was a very condensed introduction to vectors and lists. A more complete introduction is given here. 1.2.2.4 Data frames A data frame, of class \"data.frame\" is a tightly coupled collection of variables which share many of the properties of matrices and of lists, used as the fundamental data structure in R. You can think of a data frame as a table. The content of each data frame column is a vector. Columns need to be of the same length and all values in a column need to be of the same data type. A data frame can be created as follows: df &lt;- data.frame(name = c(&quot;Maria&quot;, &quot;Peter&quot;, &quot;Alex&quot;), age = c(13, 56, 30)) The elements of a data frame can be accessed the same way that we treated lists. Furthermore, they can be treated as a matrix. For example, the following code gets the first column and second row of the data frame: df[, 1] ## [1] &quot;Maria&quot; &quot;Peter&quot; &quot;Alex&quot; df[2, ] ## name age ## 2 Peter 56 You notice that the first index refers to rows and the second to columns. So to get the age of Peter, you can use one of the following options: df[2,2] ## [1] 56 df$age[2] ## [1] 56 There are many more things you can do with data frames. Since they are central to analyzing data with R, we go into more detail in Tutorial 2 and have dedicated all of Tutorial 3 to teach you how to work with data frames in a tidy way. 1.2.2.5 R environment and working directory The set of objects (variables, data frames, etc.) defined during an R session are referred to as the environment. You can view the objects in RStudio in the environment panel, grouped as Data, Values and Functions (functions that you write, which we cover in Tutorial 2). After closing an existing R session (e.g. after quitting RStudio), the environment defined by the used during that session will not be saved automatically and will be lost. To save your environment, go to the Session menu and select Save Workspace As…. This will save all your objects in a .RData file in your working directory. The working directory is the default location to which R writes to and reads files from, and you can specify it by going to Session &gt; Set Working Directory… and navigating to your desired folder. Alternatively, you can check what is your current working directory or change it by entering the following in the console: getwd() # get working directory ## [1] &quot;/home/pepa/agds&quot; setwd(&quot;~/agds&quot;) # set working directory Ideally, the working directory is a folder containing only the files relevant to your data analysis project. Next, we will go over some more sophisticated ways of writing code and saving your progress. 1.2.3 R scripts Usually, multiple statements are needed to get, e.g., from reading data into R to final numbers and figures that make up a further analysis. Together, these multiple statements constitute a workflow. It is essential that all workflows that underlie results of publications are reproducible, that is, that another person can replicate your results using your code and data. To make a workflow reproducible, the sequence of statements that you needed to carry out your analysis and produce outputs can be saved as an R script. A script is a text file named with the suffix .R to indicate that it is executable by R. It contains a sequence of R commands, which you can run all at once or one at a time. These commands will always be run line-by-line, starting from the top. To create a new script in RStudio, go to the File menu and select New File &gt; R Script. This will open a new script file in the source editor. You can then type your R code in the script file and save it to your computer. To run a script, you can either use the Source button in the source editor or use the keyboard shortcut Ctrl + Shift + Enter (Windows) or Command + Shift + Enter (Mac). This will run all of the commands in the script file, in the order they are written, in the console. Alternatively, you can type into the console: source(&quot;my_r_script.R&quot;) Note that, to be able to run the code above, the file my_r_script.R must be in your working directory. You can find more useful information about scripts and workflows in R for Data Science (Wickham2017R?). We should always strive to write nice scripts and good code. Good code is clean, readable, consistent, and extensible (easily modified or adapted). To achieve this, here are a few points to consider - inspired by best practices for coding and by the Tidyverse style guide (wickham_welcome_nodate?). 1.2.3.1 Structure your script At the beginning of each file add a header as a fully commented text section, describing what the code contains, and how it fits into the larger analysis framework. Note that Git stores all meta information about the file, including who created it, who modified it and when. This information should not be added to the header. Then, load all libraries needed within the script. Then, source any scripts and load data, and only then, start with the sequence of statements. To visually separate parts, break up your code using, commented lines. For example, a script could look like this: ##//////////////////////////////////////// ## Demonstrating script structure ##--------------------------------------- library(tidyverse) source(&quot;R/my_functions.R&quot;) my_df &lt;- read_csv(&quot;data/my_df.csv&quot;) ##--------------------------------------- ## Main part ##--------------------------------------- ## convert units my_df$temp &lt;- my_df$temp + 273.15 # deg C -&gt; K ##--------------------------------------- ## Writing output ##--------------------------------------- filn &lt;- &quot;data/my_df_kelvin.csv&quot; print(paste(&quot;Writing file&quot;, filn, &quot;...&quot;)) write_csv(my_df, filn) 1.2.3.2 Comments Adding comments in the code helps to explain exactly what the code is doing and why. This makes it easy to understand and modify the code, and can be key when debugging. In R source files, comments are prefixed with a #, which means that all what is right of the # is not interpreted by R. Avoid obsolete comments like ## take the mean myvar_mean &lt;- mean(myvar) 1.2.3.3 Spaces and breaks Adding enough white spaces and line breaks in the right locations greatly helps the legibility of any code. Cramping it up too much leads to an unintelligible sequence of characters and it will not be clear what parts go together (operators, variable names, brackets). Therefore, consider the following points: Use spaces around operators (=, +, -, &lt;-, &gt;, etc.). Use &lt;-, not =, for allocating a value to a variable. An opening curly bracket ({) should be followed by a line break and never stand alone on a line. A closing curly bracket (}) should stand alone on a line unless followed by else. Code inside curly brackets should be indented (recommended: two white spaces at the beginning of each line for each indentation level - don’t use tabs). For example, well written code looks like this: if (temp &gt; 5.0){ growth_temp &lt;- growth_temp + temp } 1.2.3.4 Variable naming It is preferable to use concise and descriptive variable names. Different variable naming styles are being used. In this course, we use lowercase letters, and underscores (_) to separate words within a name (_). Avoid (.) as they are reserved for S3 objects (base R). Also, you should avoid naming your objects with names of common functions and variables since your re-definition will mask already defined object names. For example, df_daily is a data frame with data at a daily resolution. Or clean_daily is a function that cleans daily data. Note that a verb is used as a name for a function and an underscore (_) is used to separate words. It is also recommendable to avoid variable names consisting of only one character. This makes it practically impossible to search for that variable. # Good day_01 # Bad DayOne day.one first_day_of_the_month djm1 # Very bad mean &lt;- function(x) sum(x)/length(x) # mean() itself is already a function T &lt;- FALSE # T is an abbreviation of TRUE c &lt;- 10 # c() is used to create a vector (example &lt;- c(1, 2, 3)) 1.2.3.5 R Markdown RMarkdown files are an enhanced version of scripts. They combine formatted text and executable code chunks. They can either be compiled (knitted) into an HTML or PDF output, where code chunks are executed upon compilation and visualization outputs are directly placed into the output, or they can be run like a script entirely or each code chunk separately. When run (not knitted), objects defined by the executed code are available in the environment. Text can be formatted using the Markdown syntax. For example, a top-level section title is specified by # and a title of a section one level lower by ##. RMarkdown documents are also the basis of this book, with each chapter written in a separate RMarkdown file. This lets you use the book in an interactive fashion. When opened in RStudio, you can knit an RMarkdown document by clicking the Knit button at the top of the source panel. To run the chunks of code in an RMarkdown file, you can click on the Run button also on the source panel and select an option from the drop-down menu. For example, Run All runs all the chunks in the document. Alternatively, individual chunks can be executed by clicking the green right-pointing triangle in the upper right corner of each chunk. [Screenshot of the RStudio source panel and an opened RMarkdown document.]{figures/RMarkdown.png} 1.2.4 Workspace management Using R projects in combination with Git (covered in Tutorial 6) is the essence of efficient workspace management in R. All files that belong together are organised within one directory. This can be regarded as the project directory and is typically congruent with what belongs to the respective Git repository. By keeping an organized workspace, another person (or your future self) can find relevant files, run your code and reproduce your analysis workflow easily. 1.2.4.1 R projects RStudio also allows you to work with R projects. An R project is a collection of files and folders that you use for a specific analysis or data project. An R project makes it easier to organize and manage your files and keep track of your work. To create a new R project, go to the File menu and select New Project…. This will open the New Project dialog, where you can choose where to save your project and what type of project to create. The current project that you are working on is shown on the upper right corner of the RStudio interface. Here you can also switch between existing projects or create a new one. Create R Project dialog. When starting a new project, a file &lt;project_name.Rproj&gt; is created. It sits in the project directory and stores information about your last session (settings, open files, etc.) and optionally (not recommended) the environment of that session. The use of R projects also automatically enables useful features in RStudio for easy package, website, or book building and lets you manage Git for the repository corresponding to the project. When you want to continue working on an existing R project, you can start a new session by clicking on your &lt;project_name.Rproj&gt; file. This restores settings from your last R session. Nevertheless, we recommend to start with an empty environment and load your data and variables using the code you previously wrote. That way, you ensure that your results are reproducible. 1.2.4.2 Folder structure Once you have created an R project, you can create new scripts and other files within the project. These files will be organized in a folder structure, which you can view and manage in the files, plots, help, etc. panel. For example, keep source files where R functions are defined in ./R (where . refers to the current project directory), data files in ./data and visualizations in ./fig. It’s advisable to write output files, created by the code of your project, to sub-directories within the project directory. To read and write from/to files should be done using relative paths, like any of the two equivalent following options: source(&quot;./R/my_r_script.R&quot;) source(&quot;R/my_r_script.R&quot;) A project directory should only contain code, data and outputs that belong to this one project. Stuff that may belong to multiple projects should be kept somewhere else. For example, keep original data (e.g., the raw data files that you created when collecting the data in the field, or data files you downloaded from the web) outside the project directory. Exceptions are small data files, which you can keep in ./data_raw. It is advisable to create a separate data directory outside (e.g., ~/data/, where ~ refers to your home directory) that holds all the original data you ever downloaded, or obtained from peers, or gathered yourself. Within such a data directory, you can put files from different sources into separate sub-directories and add a description file (e.g., ~/data/some_data_source/README) defining who, from where and when the data was obtained and defining data use policy. You can find an [R project template]{https://github.com/computationales/R_proj_template} in the GECO GitHub page. It shows an example of how you can organize your files into folders. Using such a template removes the overhead of designing a structure for each new project and can help you keep your work organized and make it easier to reuse and share your code. 1.3 Exercises 1.4 Solutions "],["programming_primers.html", "Chapter 2 Programming primers 2.1 Learning objectives 2.2 Tutorial 2.3 Exercises 2.4 Solutions", " Chapter 2 Programming primers Chapter lead author: Pepa Aran TBC Contents: Lecture (Beni): Models and data Base R variables, classes data frames loops conditional statements functions input and output intro to visualisation Performance assessment: link to my exercise, link to Dietze exercise 2.1 Learning objectives After you’ve gone over the lecture and solved the exercises, you should be able to: Use loops and functions in your code Install and load libraries and packages Look for help Read, inspect and visualise data frames Organize your R project for data analysis 2.2 Tutorial 2.2.1 Libraries Packages, also called libraries, are collections of R functions, data, and complied code in a well-defined format. R comes with a standard set of packages (including base R, utils, stats…) and other packages targeted for specific applications are available for download and installation. Once installed, you need to load them each time you start a new R session to use them. For example, the tidyverse package is used for data wrangling and will be covered in this course. You can install a new package as follows: install.packages(&quot;tidyverse&quot;) ## Installing package into &#39;/home/pepa/R/x86_64-pc-linux-gnu-library/4.2&#39; ## (as &#39;lib&#39; is unspecified) Then, you can load it with the following code. Note that now the name of the package is not in quotation marks. library(tidyverse) ## ── Attaching packages ───────────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.4.0 ✔ purrr 1.0.0 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.10 ## ✔ tidyr 1.2.1 ✔ stringr 1.5.0 ## ✔ readr 2.1.3 ✔ forcats 0.5.2 ## ── Conflicts ──────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() You can now use the functions and features provided by the tidyverse package in your R scripts. You can see a list of your installed packages with the following command: library() ## Warning in library(): libraries &#39;/usr/local/lib/R/site-library&#39;, ## &#39;/usr/lib/R/site-library&#39; contain no packages And a list of the packages currently loaded: search() ## [1] &quot;.GlobalEnv&quot; &quot;package:forcats&quot; &quot;package:stringr&quot; &quot;package:dplyr&quot; ## [5] &quot;package:purrr&quot; &quot;package:readr&quot; &quot;package:tidyr&quot; &quot;package:tibble&quot; ## [9] &quot;package:ggplot2&quot; &quot;package:tidyverse&quot; &quot;tools:rstudio&quot; &quot;package:stats&quot; ## [13] &quot;package:graphics&quot; &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; ## [17] &quot;package:methods&quot; &quot;Autoloads&quot; &quot;package:base&quot; This information can also be found on the Packages panel in RStudio. The loaded packages are shown with a tick mark. 2.2.1.1 Other libraries and applications For this course, we will also need software that is not available as an R package. To work with other libraries and applications, you may need to install additional software on your computer. For example, to work with netcdf files in R, you would need to install the \"ncdf4\" library and the netCDF command-line tools: - To install the \"ncdf4\" library, follow the same steps as above for installing an R library. - To install the netCDF command-line tools, follow the instructions on the [netCDF website]{https://www.unidata.ucar.edu/downloads/netcdf/index.jsp}. - Once the \"ncdf4\" library and the netCDF command-line tools are installed, you can use them to work with .nc files in R. For example, you could use the nc_open() function from the \"ncdf4\" library to open a file. 2.2.2 Working with data frames In the first tutorial, we introduced data frames as an R object. Now, let’s get our hands on actual data for demonstrating how data is read and written. As most of the code displayed in this book, the code chunks below are executable. You can try it out by opening the the book’s R project in RStudio. We are going to work with data from ecosystem flux measurements, taken by the eddy covariance technique, and provided as part of the FLUXNET2015 dataset (Pastorello2020?), which you can see here. The data we’re using below comes from a flux tower near Zürich (CH-Lae, located on the Laegern mountain between Regensberg and Baden and run by our colleagues at ETH). The data is stored as a Comma Separated Values file (.csv). This is a plain-text, and therefore a non-proprietary format. To follow the open science principles for data, distribute your data in a format that is non-proprietary and readable across platforms and applications. For example, avoid distributing your data as an Excel spreadsheat (.xlsx), or a Matlab data object (.mat), or an R data object (.RData, or .rds). 2.2.2.1 Reading data To import the data into the R environment, we use the function read_csv() from the tidyverse package. In other R code, you will also encounter the base R read.csv() function. However, read_csv() is much faster and reads data into a tidyverse-data frame (a tibble) which has some useful additional characteristics, on top of a common R data frame. To tell the function where the data is located, pass the data’s path as an argument. You can either use an absolute path, starting from C:/ on a Windows computer or ~/ on a Mac or Linux. Or, alternatively, you can provide a relative path, where ./ points to the present working directory and ../ is one level up, or ../../ is two levels up, etc. We recommend that you work with R projects and use relative paths, because the working directory is set to the root directory of the R project and relative paths will also work on another person’s computer, helping with reproducibility. # use a relative path to read the data df &lt;- read_csv(&quot;./data/FLX_CH-Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv&quot;) print(df) # to print an overview of the data frame ## # A tibble: 4,018 × 334 ## TIMESTAMP TA_F_MDS TA_F_MD…¹ TA_F_…² TA_F_…³ TA_F_…⁴ TA_F_…⁵ TA_F_…⁶ TA_F_…⁷ TA_ERA ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20040101 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -2.38 ## 2 20040102 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -2.85 ## 3 20040103 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -5.79 ## 4 20040104 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -5.99 ## 5 20040105 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -2.03 ## 6 20040106 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 0.387 ## 7 20040107 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 0.154 ## 8 20040108 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 0.888 ## 9 20040109 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 2.84 ## 10 20040110 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 1.80 ## # … with 4,008 more rows, 324 more variables: TA_ERA_NIGHT &lt;dbl&gt;, ## # TA_ERA_NIGHT_SD &lt;dbl&gt;, TA_ERA_DAY &lt;dbl&gt;, TA_ERA_DAY_SD &lt;dbl&gt;, TA_F &lt;dbl&gt;, ## # TA_F_QC &lt;dbl&gt;, TA_F_NIGHT &lt;dbl&gt;, TA_F_NIGHT_SD &lt;dbl&gt;, TA_F_NIGHT_QC &lt;dbl&gt;, ## # TA_F_DAY &lt;dbl&gt;, TA_F_DAY_SD &lt;dbl&gt;, TA_F_DAY_QC &lt;dbl&gt;, SW_IN_POT &lt;dbl&gt;, ## # SW_IN_F_MDS &lt;dbl&gt;, SW_IN_F_MDS_QC &lt;dbl&gt;, SW_IN_ERA &lt;dbl&gt;, SW_IN_F &lt;dbl&gt;, ## # SW_IN_F_QC &lt;dbl&gt;, LW_IN_F_MDS &lt;dbl&gt;, LW_IN_F_MDS_QC &lt;dbl&gt;, LW_IN_ERA &lt;dbl&gt;, ## # LW_IN_F &lt;dbl&gt;, LW_IN_F_QC &lt;dbl&gt;, LW_IN_JSB &lt;dbl&gt;, LW_IN_JSB_QC &lt;dbl&gt;, … The file is automatically machine-readable because we have: Only one header row, containing the column (variable) names. Variables organised by columns, and observations by rows. Each column consists of a single data type (e.g., character, numeric, logical; see below for more info). Here, all columns are interpreted as numeric (`’). One value per cell. No merged cells. In short, the data frame is tidy. To understand the sort of object we work with, i.e. the class, we can do: class(df) ## [1] &quot;spec_tbl_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Fundamentally, df is a data.frame. In addition, it is also of some other classes (spec_tbl_df\", \"tbl_df\", \"tbl\") which gives it additional features. 2.2.2.2 Understanding the data structure There are several base R functions to help you understand the structure of a data frame. Here is a non-exhaustive list of of them: Size dim() - Returns the dimensions of an object (here: number of rows and columns). nrow() - Returns the number of rows of an object. ncol() - Returns the number of columns of an object. Content head() - Returns the first 6 rows. tail() - Returns the last 6 rows. View() - Opens a window in the source panel in RStudio where you can look at the entire data set in the form of a table (It is not supported by the Jupyter environment). Names names() - Returns the column names (for data.frame objects it is synonymous to colnames()). rownames() - Returns the row names. Summary class() - Returns the classes of an object. str() - Returns the structure of an object and information about the class, length and content of each column. summary() - Returns generic statistics information, depending on the class of the object. For categorical variables it will show how common each class is, missing values, etc, and for numerical variables, the mean, quantiles, maximum and minimum values, etc. For example, the data frame df has 4018 rows and 334 columns: dim(df) ## [1] 4018 334 It is important to know the meaning of the column namesA description of standardized FLUXNET data variables is available here. A selection of available variables that we will use in subsequent chapters are: GPP (gC m\\(^{−2}\\) s\\(^{-1}\\)): Gross primary production WS (m s\\(^{-1}\\)): Horizontal wind speed USTAR (m s\\(^{-1}\\)): Friction velocity TA (\\(^{o}\\) C): Air temperature RH (%): Relative humidity (range 0–100%) PA (kPa): Atmospheric pressure G (W m\\(^{−2}\\)): Ground heat flux, not mandatory, but needed for the energy balance closure calculations NETRAD (W m\\(^{−2}\\)): Net radiation, not mandatory, but needed for the energy balance closure calculations SW_IN (W m\\(^{−2}\\)): Incoming shortwave radiation SW_IN_POT (W m\\(^−2\\)): Potential incoming shortwave radiation (top of atmosphere theoretical maximum radiation) PPFD_IN (\\(\\mu\\)mol photons m\\(^{−2}\\) s\\(^{-1}\\)): Incoming photosynthetic photon flux density P (mm): Precipitation total of each 30 or 60 minute period LW_IN (W m\\(^{−2}\\)): Incoming (down-welling) long-wave radiation SWC (%): Soil water content (volumetric), range 0–100% TS (\\(^{o}\\) C): Soil temperature CO2 (\\(\\mu\\)molCO2 mol\\(^{-1}\\)): Carbon dioxide (CO\\(_2\\)) mole fraction in moist air 2.2.2.3 Selecting data and entering the tidyverse df is a data frame. This is similar to a matrix and has two dimensions (rows and columns). If we want to extract specific data from it, we specify the indices, i.e. the “coordinates”, of the data. For two-dimensional objects (data frames, matrices), the first index refers to rows and the second to columns. For example, to refer to the element on the third row in the first column, we write: df[3,1] ## # A tibble: 1 × 1 ## TIMESTAMP ## &lt;dbl&gt; ## 1 20040103 Reducing a data frame (tibble) to only the first columns can be done by: df[, 1] ## # A tibble: 4,018 × 1 ## TIMESTAMP ## &lt;dbl&gt; ## 1 20040101 ## 2 20040102 ## 3 20040103 ## 4 20040104 ## 5 20040105 ## 6 20040106 ## 7 20040107 ## 8 20040108 ## 9 20040109 ## 10 20040110 ## # … with 4,008 more rows The method of selecting parts of a data frame by index is quite flexible. For example, we may require the information in the third column for the first three rows. Putting a colon between two numbers, e.g. [1:3,], indicates we want to select the rows numbers starting at the first and ending with the second number. So here [1:3,] will give us rows one, two and three. df[1:3, 3] # reduces the data frame (tibble) to its first three rows and the 3rd column ## # A tibble: 3 × 1 ## TA_F_MDS_QC ## &lt;dbl&gt; ## 1 -9999 ## 2 -9999 ## 3 -9999 To reduce the data frame (tibble) to several columns, the function c() is used. c() stands for concatenate, which means to link together in a series or chain. This outputs the data frame (tibble) reduced to the selected row or column numbers inside c(). df[, c(1,4,7)] ## # A tibble: 4,018 × 3 ## TIMESTAMP TA_F_MDS_NIGHT TA_F_MDS_DAY ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20040101 -9999 -9999 ## 2 20040102 -9999 -9999 ## 3 20040103 -9999 -9999 ## 4 20040104 -9999 -9999 ## 5 20040105 -9999 -9999 ## 6 20040106 -9999 -9999 ## 7 20040107 -9999 -9999 ## 8 20040108 -9999 -9999 ## 9 20040109 -9999 -9999 ## 10 20040110 -9999 -9999 ## # … with 4,008 more rows Another method is to select the columns by column names, i.e. giving as input a string vector with the name of each column we want to select (again, this is Base R notation). This is especially useful if the columns we want to select are not contiguous. For example: # Selecting data by name in base R df[,c(&quot;TIMESTAMP&quot;, &quot;TA_F_MDS&quot;, &quot;TA_F_MDS_QC&quot;)] ## # A tibble: 4,018 × 3 ## TIMESTAMP TA_F_MDS TA_F_MDS_QC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20040101 -9999 -9999 ## 2 20040102 -9999 -9999 ## 3 20040103 -9999 -9999 ## 4 20040104 -9999 -9999 ## 5 20040105 -9999 -9999 ## 6 20040106 -9999 -9999 ## 7 20040107 -9999 -9999 ## 8 20040108 -9999 -9999 ## 9 20040109 -9999 -9999 ## 10 20040110 -9999 -9999 ## # … with 4,008 more rows In Tutorial 3, we will use the tidyverse, which is a set of R packages designed for working with tidy data and writing code in a way that makes the “workflow” more clear and understandable. A code chunk which does the same as above, but is written for the tidyverse can read as follows. select(df, 1) # reduces the data frame (tibble) to its first column ## # A tibble: 4,018 × 1 ## TIMESTAMP ## &lt;dbl&gt; ## 1 20040101 ## 2 20040102 ## 3 20040103 ## 4 20040104 ## 5 20040105 ## 6 20040106 ## 7 20040107 ## 8 20040108 ## 9 20040109 ## 10 20040110 ## # … with 4,008 more rows select(df, TIMESTAMP, TA_F_MDS, TA_F_MDS_QC) # reduces the data frame to columns specified by names ## # A tibble: 4,018 × 3 ## TIMESTAMP TA_F_MDS TA_F_MDS_QC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20040101 -9999 -9999 ## 2 20040102 -9999 -9999 ## 3 20040103 -9999 -9999 ## 4 20040104 -9999 -9999 ## 5 20040105 -9999 -9999 ## 6 20040106 -9999 -9999 ## 7 20040107 -9999 -9999 ## 8 20040108 -9999 -9999 ## 9 20040109 -9999 -9999 ## 10 20040110 -9999 -9999 ## # … with 4,008 more rows As a further shortcut in tidyverse, we can use the pipe %&gt;% operator. The data frame is still reduced to its first column: df %&gt;% select(1) ## # A tibble: 4,018 × 1 ## TIMESTAMP ## &lt;dbl&gt; ## 1 20040101 ## 2 20040102 ## 3 20040103 ## 4 20040104 ## 5 20040105 ## 6 20040106 ## 7 20040107 ## 8 20040108 ## 9 20040109 ## 10 20040110 ## # … with 4,008 more rows We pipe the object df into the select() function with argument 1. Note that the pipe operator %&gt;% can be used on any function. It tells the function to interpret what’s coming from the left of %&gt;% as its first argument. For the remainder of the tutorial several variables will be required. The methods of data selection demonstrated above will be used below to get the desired variables. df_small &lt;- df %&gt;% select(TIMESTAMP, TA_F, PPFD_IN) Note: In the code above, an indentation was used to highlight which parts go together, which makes the code easy to understand. Indentations and line breaks have no meaning or function in R per se (unlike in other programming languages, e.g., Matlab, Python), but help to make the code easier to read. 2.2.2.4 Renaming TIMESTAMP_START, TA_F and PPFD_IN as variable names may be hard to remember and in this section you will have to type them a lot. Therefore we change their names to something more intelligible. df_small &lt;- df_small %&gt;% rename(time = TIMESTAMP, temp = TA_F, ppfd = PPFD_IN) 2.2.2.5 Writing data A data frame can be written to a CSV file by: write_csv(df_small, path = &quot;data/df_small.csv&quot;) The function saveRDS() allows you save individual R objects of any form (not just a data frame). saveRDS() creates a binary file that is fast to write and read, but only intelligible to R. Such files are commonly identified by the suffix .rds. It is recommended to name the .rds files according to the single object they contain. For example: saveRDS(df_small, file = &quot;data/df_small.rds&quot;) This file can then be read into the R environment. Sometimes, it is useful to give it a new name, e.g.: df_small &lt;- readRDS(&quot;data/df_small.rds&quot;) Note that making a file publicly available as a .rds file violates the open science principles. It is not interoperable. Therefore, whenever possible, save your data in a format that is readable across platforms without requiring proprietary software. Hence use write_csv() whenever possible. We will encounter other non-proprietary formats that let you save and share more complex data structures in Tutorial 5. 2.2.3 Programming basics In this section, we will review the most basic programming elements (conditional statements, loops, functions…) for the R syntax. 2.2.3.1 Conditional statements In cases where we want certain statements to be executed or not, depending on a criterion, we can use conditional statements if, else if, and else. Conditionals are an essential feature of programming and available in all languages. The R syntax for conditional statements looks like this: if (temp &lt; 0.0){ is_frozen &lt;- TRUE } The evaluation of the criterion (here (temp &lt; 0.0)) has to return either TRUE or FALSE. Whenever the statement between parenthesis is true, the chunk of code between curly brackets is executed. Otherwise, nothing happens. if (temp &lt; 0.0){ is_frozen &lt;- TRUE } else { is_frozen &lt;- FALSE } You can also write a conditional that covers all possibilities, like the one above. When the temperature is below 0, the first chunk of code is executed. Whenever it is greater or equal that 0 (i.e. the condition returns FALSE) the second chunk of code is evaluated. You can also write more than two conditions, covering several cases. Conditionals are evaluated in order, so if the first condition is not true, it checks the second. If the second is false, it checks the third, and so on. The statements after else are evaluated when everything before was FALSE. 2.2.3.2 Loops Loops are another essential feature of programming. for and while loops exist in probably all programming languages. We introduce them here because they are a simple and powerful tool for solving many common tasks. for and while loops let us repeatedly execute the same set of commands, while changing an index or counter variable to take a sequence of different values. The following example calculates the sum of the first ten temperature values in df, by iteratively adding them together. Of course, this is equivalent to just using the sum() function. temp_sum &lt;- 0 # initialize sum for (i in 1:10){ temp_sum &lt;- temp_sum + df_small$temp[i] } print(temp_sum) ## [1] -12.97 print(sum(df_small$temp[1:10])) ## [1] -12.97 Instead of directly telling R how many iterations it should do we can also define a condition. As long as the condition is TRUE, R will continue iterating. As soon as it is FALSE, R stops the loop. The following lines of code do the same operation as the for loop we just wrote. What is different? What is the same? i = 1 # initialize counter temp_sum &lt;- 0 # initialize sum while (i &lt;= 10){ temp_sum &lt;- temp_sum + df_small$temp[i] i = i+1 } print(temp_sum) ## [1] -12.97 print(sum(df_small$temp[1:10])) ## [1] -12.97 2.2.3.3 Functions Often, analyses require many steps and your scripts may get excessively long. Over 2000 lines of code in one file are hard to digest. An important aspect of good programming is to avoid duplicating code. If the same sequence of multiple statements or functions are to be applied repeatedly to different objects, then it is usually advisable to bundle them into a new function and apply this single function to each object. This also has the advantage that if some requirement or variable name changes, it has to be edited only in one place. A further advantage of writing functions is that you can give the function an intuitively understandable name, so that your code reads like a sequence of orders given to a human. For example, the following code, converting temperature values provided in Fahrenheit to degrees Celsius, could be turned into a function. ## NOT ADVISABLE temp_soil &lt;- (temp_soil - 32) * 5 / 9 temp_air &lt;- (temp_air - 32) * 5 / 9 temp_leaf &lt;- (temp_leaf - 32) * 5 / 9 Functions are a set of instructions encapsulated within curly brackets ({}) that generate a desired outcome. Functions contain three main elements: - They start with a name to describe their purpose, - then they need arguments, which are a list of the objects being input, - and lastly enclosed by curly brackets function(x){ ... } the code making up the ‘body’ of the function. They become increasingly important the more experienced one gets at coding. Using functions minimises the amount of code being re-written, decreases accidental errors when retyping code and are key to keeping a clean workspace. Functions have their own environment, which means variables within the function are only ‘live’ or used when the function is running but are not saved to the global environment unless they are part of the output of the function. A good moment to think about using a function is when sections of code are being repeated again and again. Whenever possible, we should combine multiple processing steps that naturally belong together. Specifically, when the same sequence of steps must be applied to multiple datasets that have the same structure (variable names, etc.). We can combine the set of operations presented above into a single function. Once such a function is created, we can apply it to the data in one go, instead of repeating the successive steps. We will now write our first function and implement the data cleaning steps we described above. The function consists of multiple sequences of code as it contains the different steps presented above and applies them sequentially. The same, but using our own function convert_fahrenheit_to_celsius(): ## ADVISABLE convert_fahrenheit_to_celsius &lt;- function(temp_f){ temp_c &lt;- (temp_f - 32) * 5 / 9 } temp_soil &lt;- convert_fahrenheit_to_celsius(temp_soil) temp_air &lt;- convert_fahrenheit_to_celsius(temp_air) temp_leaf &lt;- convert_fahrenheit_to_celsius(temp_leaf) Functions (particularly long ones) can be written to separate source files. These R scripts containing only function definitions can be saved in your ./R directory, to keep your workspace organized. Preferably, the file has the same name as the function. 2.2.3.4 Input and output A good practice when writing a function is to document what the function does, the meaning and structure of every input (argument) and the output (value) of the function. 2.2.4 Intro to visualisation Visualising data is an integral part of any data science workflow. In this section, we introduce just the very basics. In later tutorials, you will get introduced to additional methods for visualising data. Our data frame fluxes_subset contains three variables, one of which is time. In other words, we are dealing with a time series. Let’s look at the temporal course of temperature in the first 1440 time steps (corresponding to 30 days) as a line plot (type = \"l\"). plot(1:1440, df_small$temp[1:1440], type = &quot;l&quot;) Another useful way of looking, not at a temporal course, but rather at the distribution of your data, is to display a histogram. A histogram visualises the frequency or proportion of data that has a metric value that falls within a certain interval known as a ‘bin’. Below you will see the temperature on the x-axis split into these ‘bins’ ranging across 2°. The number of times a data point falls between say 2° to 4° is then tallied and displayed as the frequency on the y-axis. Here there are around 1500 temperature values between 2° and 4°. hist(df_small$temp, xlab = &quot;Temperature (°C)&quot;) Plots can be saved as files, as long as the file size does not get too large.It will write vector graphics as outputs, i.e. PDF. In base R, this can be done by: pdf(&quot;./figures/filename.pdf&quot;) hist(df_small$temp) 2.2.5 Where to find help 2.3 Exercises 2.4 Solutions "],["data_wrangling.html", "Chapter 3 Data wrangling 3.1 Learning objectives 3.2 Tutorial 3.3 Exercises 3.4 Solutions", " Chapter 3 Data wrangling Chapter lead author: Benjamin Stocker Contents: Lecture (Beni): Tidy data, “bad” data Data frame manipulations with tidyverse Tidy data Dealing with missingness, bad data, outliers Imputation (note also imputation as part of the modelling workflow) Performance assessment: CAT 1, link, Make table tidy 3.1 Learning objectives 3.2 Tutorial 3.3 Exercises 3.4 Solutions "],["data_vis.html", "Chapter 4 Data visualisation 4.1 Learning objectives 4.2 Tutorial 4.3 Exercises 4.4 Solutions", " Chapter 4 Data visualisation Chapter lead author: Benjamin Stocker Contents: Lecture (Isabelle Bentz?): The art of visualising data, grammar of graphics Exercise: Develop decision tree for what type of visualisation to apply Performance assessment: Interactive work sequence 4.1 Learning objectives 4.2 Tutorial 4.3 Exercises 4.4 Solutions "],["data_variety.html", "Chapter 5 Data variety 5.1 Learning objectives 5.2 Tutorial 5.3 Exercises 5.4 Solutions", " Chapter 5 Data variety Chapter lead author: Koen Hufkens Contents: Lecture (Mirko): Mapping data Data formats, standards, metadata Geographic data Scraping, wget APIs 5.1 Learning objectives 5.2 Tutorial 5.3 Exercises 5.4 Solutions "],["code_mgmt.html", "Chapter 6 Code management 6.1 Learning objectives 6.2 Tutorial 6.3 Exercises 6.4 Solutions", " Chapter 6 Code management Chapter lead author: Koen Hufkens Contents: git: repositories, stage, commit, push, fork, pull request, fetch upstream Performance assessment: CAT 2 6.1 Learning objectives 6.2 Tutorial 6.3 Exercises 6.4 Solutions "],["open_science.html", "Chapter 7 Open science practices 7.1 Learning objectives 7.2 Tutorial 7.3 Exercises 7.4 Solutions", " Chapter 7 Open science practices Chapter lead author: Koen Hufkens Contents: Lecture (Koen): Open science - history, motivation, reproducibility crisis, current initiatives, overview of practices Environmental data repositories Methods to create visualised reproducible workflow RMarkdown files Performance assessment: CAT 3, link to Dietze exercise on pair coding 7.1 Learning objectives 7.2 Tutorial 7.3 Exercises 7.4 Solutions "],["regression.html", "Chapter 8 Regression 8.1 Learning objectives 8.2 Tutorial 8.3 Exercises 8.4 Solutions", " Chapter 8 Regression Chapter lead author: Benjamin Stocker Contents: Linear regression Regression metrics Logistic regression classification metrics Comparing models (AIC, …) Feature selection, stepwise regression, multi-colinearity (vif) Performance assessment: Exercise for stepwise regression link 8.1 Learning objectives 8.2 Tutorial 8.3 Exercises 8.4 Solutions "],["supervised_ml.html", "Chapter 9 Supervised machine learning 9.1 Learning objectives 9.2 Tutorial 9.3 Exercises 9.4 Solutions", " Chapter 9 Supervised machine learning Chapter lead author: Benjamin Stocker Lecture (Beni): Overfitting, training, and cross-validation (link) K nearest neighbour models Data splitting Preprocessing, standardization, imputation, dimension reduction, as part of the model training workflow formula notation, recipes, generic train() Training and loss function Hyperparameters Resampling Performance assessment: Exercise comparing performance on test set of linear regression and KNN with different hyperparameter choices (like this), discuss link to overfitting example 9.1 Learning objectives 9.2 Tutorial 9.3 Exercises 9.4 Solutions "],["random_forest.html", "Chapter 10 Random forest 10.1 Learning objectives 10.2 Tutorial 10.3 Exercises 10.4 Solutions", " Chapter 10 Random forest Chapter lead author: Benjamin Stocker Contents: Lecture (Beni): Wisdom of the crowds, from decision trees to random forests Performance assessment: Competition for best-performing model, given training-testing split of data; others should be able to reproduce performance 10.1 Learning objectives 10.2 Tutorial 10.3 Exercises 10.4 Solutions "],["neural_nets.html", "Chapter 11 Neural networks 11.1 Learning objectives 11.2 Tutorial 11.3 Exercises 11.4 Solutions", " Chapter 11 Neural networks Chapter lead author: Benjamin Stocker Contents: Lecture (Beni): General introduction Performance assessment: Competition for best-performing model, given training-testing split of data; others should be able to reproduce performance 11.1 Learning objectives 11.2 Tutorial 11.3 Exercises 11.4 Solutions "],["interpretable_ml.html", "Chapter 12 Interpretable machine learning 12.1 Learning objectives 12.2 Tutorial 12.3 Exercises 12.4 Solutions", " Chapter 12 Interpretable machine learning Chapter lead author: Benjamin Stocker Contents: Variable importance Partial dependency Performance assessment: Compare partial dependency to a given predictor, detected with RF and with NN. 12.1 Learning objectives 12.2 Tutorial 12.3 Exercises 12.4 Solutions "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
